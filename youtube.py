import requests
from bs4 import BeautifulSoup
from datetime import datetime

HEADERS = {"User-Agent": "Mozilla/5.0"}

def resolve_channel(url: str) -> str | None:
    if "youtube.com" not in url:
        return None
    if "/@" in url:
        return url.rstrip("/")
    return None

def get_channel_info(channel_url: str) -> dict | None:
    try:
        r = requests.get(channel_url, headers=HEADERS, timeout=10)
        if r.status_code != 200:
            return None

        soup = BeautifulSoup(r.text, "html.parser")
        og_title = soup.find("meta", property="og:title")
        og_url = soup.find("meta", property="og:url")
        if not og_title or not og_url:
            return None

        title = og_title["content"].replace(" - YouTube", "").strip()
        url = og_url["content"]
        return {"title": title, "url": url}
    except Exception:
        return None

# üîπ –ü—Ä–∏–º–µ—Ä —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≤–∏–¥–µ–æ
def get_latest_video(channel_url: str) -> dict | None:
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å API YouTube –∏–ª–∏ –ø–∞—Ä—Å–µ—Ä RSS –∫–∞–Ω–∞–ª–∞
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å: {"id": video_id, "title": title, "published": iso_date, "url": video_url}
    # –î–ª—è —Ç–µ—Å—Ç–∞ –º–æ–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å –∑–∞–≥–ª—É—à–∫—É
    return {
        "id": "test_id",
        "title": "–¢–µ—Å—Ç–æ–≤–æ–µ –≤–∏–¥–µ–æ",
        "published": datetime.utcnow().isoformat(),
        "url": f"{channel_url}/video/test_id"
    }
